# MachineLearning_ID3_KNN_NaiveBayes
This projects implements a KNN, Navie Bayes, and ID3 classifiers to predict different class attributes for data sets with nominal attributes

For my Naive Bayes classifier, I implemented a 3D vector with the first layer as the attributes, second the domain of the attributes and third as the counts of democrats or republicans with those attributes. For examples myVector[0][0][0] finds the number of democrats or republicans that voted yes, no, or u on a certain issue. When loading the training data, I add a one to each of the positions in the vector, which implements the additive smoothing tactic. I also find the total number of class attributes in the load training set. In the classify method, I go through each element in an example, find the number of counts and then calculate a conditional probability. I then multiply the conditional probabilities together and then use Bayes’ Theorem. I calculate Bayes’ Theorem for all the class attributes and return the class attribute with the largest probability. My accuracy is extremely low because I was having an issue counting the total number of class attributes in the data set, which is throwing off my probability calculations. For KNN, I implement a set of parallel vectors, one holding the distances and the other holding the class attributes. I then store the “k” nearest neighbors, vote on the neighbors and return the class attribute.

